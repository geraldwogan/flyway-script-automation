{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating the DDL Scripts\n",
    "\n",
    "1. Create ETL Table file\n",
    "1. Create Stages and Pipes file\n",
    "1. Create Foundation Table file\n",
    "1. Create afterMigrateError file\n",
    "1. Create Add Format file\n",
    "\n",
    "Data we need from the excel mappings document (Table Info)\n",
    "| Item | Example |\n",
    "|-|-|\n",
    "|Table Name |DW_MBR_PCP|\n",
    "|Column Name |DW_MBR_PCP_REC_ID|\n",
    "|Column Data Type |TEXT(1000)|\n",
    "|Column Nullability |NULL or NOT NULL|\n",
    "|Key Info|Primary, Unique, ~~Foreign~~|\n",
    "|Comment|'Key for the table'|\n",
    "\n",
    "---\n",
    "Data created manually (General Snowflake Info)\n",
    "| Item | Example |\n",
    "|-|-|\n",
    "|Database |ECT_DEV_ELIGIBILITY_DB|\n",
    "|Schema/Prefix |ETL or FOUNDATION|\n",
    "|Environment |DEV, STG, PRD|\n",
    "|Format| JSON or AVRO|\n",
    "|Version| 'R', 'V1', 'V2'|\n",
    "|Flyway History Table| flyway_schema_history|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Member PCP (CDB) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from excel sheet\n",
    "excel_data_df = pd.read_excel('data/excel_mapping_docs/MEMBER_PCP_MAPPING_DOC.xlsx', sheet_name='Member_pcp_dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATATYPE</th>\n",
       "      <th>INDEX_TYPE</th>\n",
       "      <th>NULL_OPTION</th>\n",
       "      <th>COLUMN_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DW_MBR_PCP</td>\n",
       "      <td>DW_MBR_PCP_REC_ID</td>\n",
       "      <td>STRING(1000)</td>\n",
       "      <td>PRIMARY KEY</td>\n",
       "      <td>Not Null</td>\n",
       "      <td>Key for the table . Usually composite combinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DW_MBR_PCP</td>\n",
       "      <td>DW_SYS_REF_CD</td>\n",
       "      <td>STRING(1000)</td>\n",
       "      <td>UNIQUE KEY</td>\n",
       "      <td>Null</td>\n",
       "      <td>DW Source System Reference Code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DW_MBR_PCP</td>\n",
       "      <td>MBR_PCP_ID</td>\n",
       "      <td>STRING(1000)</td>\n",
       "      <td>UNIQUE KEY</td>\n",
       "      <td>Null</td>\n",
       "      <td>Key for the table . Usually composite combinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DW_MBR_PCP</td>\n",
       "      <td>MBRSHP_SRC_ID</td>\n",
       "      <td>STRING(1000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Null</td>\n",
       "      <td>Membership Individual Identifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DW_MBR_PCP</td>\n",
       "      <td>INDV_SRC_ID</td>\n",
       "      <td>STRING(1000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Null</td>\n",
       "      <td>Individual Identifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TABLE_NAME        COLUMN_NAME      DATATYPE   INDEX_TYPE NULL_OPTION  \\\n",
       "0  DW_MBR_PCP  DW_MBR_PCP_REC_ID  STRING(1000)  PRIMARY KEY    Not Null   \n",
       "1  DW_MBR_PCP      DW_SYS_REF_CD  STRING(1000)   UNIQUE KEY        Null   \n",
       "2  DW_MBR_PCP         MBR_PCP_ID  STRING(1000)   UNIQUE KEY        Null   \n",
       "3  DW_MBR_PCP      MBRSHP_SRC_ID  STRING(1000)          NaN        Null   \n",
       "4  DW_MBR_PCP        INDV_SRC_ID  STRING(1000)          NaN        Null   \n",
       "\n",
       "                                      COLUMN_COMMENT  \n",
       "0  Key for the table . Usually composite combinat...  \n",
       "1                    DW Source System Reference Code  \n",
       "2  Key for the table . Usually composite combinat...  \n",
       "3                   Membership Individual Identifier  \n",
       "4                              Individual Identifier  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Snowflake table names\n",
    "t_name = 'TABLE_NAME'\n",
    "# Snowflake column names\n",
    "column_name = 'COLUMN_NAME'\n",
    "# Column datatype\n",
    "datatype = 'DATATYPE'\n",
    "# Info regarding Primary, Foreign and Unique Keys\n",
    "key_info = 'INDEX_TYPE'\n",
    "# Info on column nullability\n",
    "nullability = 'NULL_OPTION'\n",
    "# Column comment\n",
    "column_comment = 'COLUMN_COMMENT'\n",
    "\n",
    "# Reduce the df to just the info required.\n",
    "df = excel_data_df.loc[:,[t_name, column_name, datatype, key_info, nullability, column_comment]]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all datatypes uppercase for uniformity. \n",
    "df[datatype] = df[datatype].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STRING(1000)     71\n",
       "INTEGER          27\n",
       "TIMESTAMP(3)     16\n",
       "VARCHAR2(10)     13\n",
       "VARIANT          10\n",
       "VARCHAR(10)       7\n",
       "CHAR(1)           5\n",
       "DATE              4\n",
       "STRING(100)       2\n",
       "VARCHAR2(20)      2\n",
       "VARCHAR2(100)     1\n",
       "Name: DATATYPE, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the datatypes\n",
    "df[datatype].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider identifier type code , Only Populated when Key Type is 'Provider ID' OR \"Native Provider ID\"\n",
      "Provider identifier type code , Only Populated when Key Type is 'Provider ID' OR 'Native Provider ID'\n"
     ]
    }
   ],
   "source": [
    "# Ensure there are no quotation marks (' OR \" OR \\\") that cause code to fail, only (\\') is allowed.\n",
    "print(df[column_comment][121])\n",
    "\n",
    "# df[column_comment] = df[column_comment].str.replace(\"\\'\", \"\\'\")\n",
    "df[column_comment] = df[column_comment].str.replace(\"'\", \"\\'\")\n",
    "df[column_comment] = df[column_comment].str.replace('\"', \"\\'\")\n",
    "df[column_comment] = df[column_comment].str.replace(\"\\\"\", \"\\'\")\n",
    "\n",
    "print(df[column_comment][121])\n",
    "# [ord(c) for c in df[column_comment][121][-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change TIMESTAMP to CREATE_TIMESTAMP() - Possible future solution for value needed by Compaction logic\n",
    "# df = df.replace('TIMESTAMP(3)','CURRENT_TIMESTAMP()')\n",
    "# df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check dataframe datatypes against snowflake datatypes (Deprecated: Trust the excel file instead for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowflake_dtypes = ['NUMBER','DECIMAL','NUMERIC','INT','INTEGER','BIGINT','SMALLINT','TINYINT','BYTEINT','FLOAT','FLOAT4','FLOAT8','DOUBLE','DOUBLE PRECISION', 'REAL','VARCHAR','CHAR','CHARACTER','STRING','TEXT','BINARY','VARBINARY','BOOLEAN','DATE','DATETIME','TIME','TIMESTAMP','TIMESTAMP_LTZ','TIMESTAMP_NTZ', 'TIMESTAMP_TZ','VARIANT', 'OBJECT','ARRAY','GEOGRAPHY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dtypes = df[datatype].value_counts().keys().tolist()\n",
    "# df_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: functionality to test the numbers after each datatype too.\n",
    "# for datatype in df_dtypes:\n",
    "#     datatype = datatype.split(\"(\")[0]\n",
    "#     if datatype not in snowflake_dtypes:\n",
    "#         raise Exception(f'ERROR - \"{datatype}\" is not an acceptable data type in Snowflake /nSee here for a list of acceptable data types: https://docs.snowflake.com/en/sql-reference/intro-summary-data-types.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Replace Table output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateUniqueKeyOutput(uk):\n",
    "    '''\n",
    "    Returns a string of a table unique keys for use in an SQL query.\n",
    "\n",
    "        Parameters: \n",
    "            uk (List): A List of unique keys in the current table.\n",
    "\n",
    "        Returns:\n",
    "            uk_output (str): A string for use in an SQL (CREATE TABLE) query.\n",
    "    '''\n",
    "    if len(uk) > 0:\n",
    "        uk_output = f',\\n\\t'# CONSTRAINT {table_name}_AK1 UNIQUE ('\n",
    "\n",
    "        uk_output = f',\\n\\tUNIQUE('\n",
    "        for key in uk:\n",
    "            uk_output += ''+key+','\n",
    "        uk_output = uk_output.rstrip(',')\n",
    "        uk_output += ')\\n),'\n",
    "\n",
    "    return uk_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateForeignKeyOutput(fk): # Deprecated: Foreign Keys don't matter in Snowflake.\n",
    "    if len(fk) > 0:\n",
    "        fk_output = f',\\n\\t FOREIGN KEY ('\n",
    "        for key in fk:\n",
    "            fk_output += ''+key+','\n",
    "        fk_output += ')'\n",
    "\n",
    "        # fk_output = f',\\n\\t CONSTRAINT {table_name}_AK1 FOREIGN KEY ('\n",
    "        # for key in fk:\n",
    "        #     fk_output += ''+key+','\n",
    "        fk_output += ' REFERENCES DW_MBR_PCP ('\n",
    "        for key in fk:\n",
    "            fk_output += ''+key+','\n",
    "\n",
    "        fk_output = fk_output.rstrip(',')\n",
    "        fk_output += ')\\n),'\n",
    "    return fk_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateETLTables(df, schema):\n",
    "    '''\n",
    "    Returns a string for numerous CREATE OR REPLACE TABLE SQL queries.\n",
    "\n",
    "        Parameters: \n",
    "            df (Dataframe): A Dataframe with data needed for table creation.\n",
    "\n",
    "        Returns:\n",
    "            output (str): An SQL query to create tables.\n",
    "    '''\n",
    "\n",
    "    # Initialize output to be append to later\n",
    "    output = ''\n",
    "\n",
    "    # Loop through each table in data\n",
    "    tables = df.groupby(t_name)\n",
    "\n",
    "    for table_name, table in tables:\n",
    "\n",
    "        uk = [] # Unique Keys list\n",
    "        # fk = [] # Foreign Keys list\n",
    "        \n",
    "        output += f'\\nCREATE OR REPLACE TABLE {schema}.{table_name} \\n('\n",
    "\n",
    "        for i, row in table.iterrows():\n",
    "\n",
    "            output += f'\\n\\t{row[column_name]} {row[datatype]} {row[nullability]} COMMENT \"{row[column_comment]}\",'\n",
    "            \n",
    "            if 'PRIMARY KEY' in str(row[key_info]):\n",
    "                pk = f',\\n\\tPRIMARY KEY ({row[column_name]})'\n",
    "                \n",
    "            if 'UNIQUE KEY' in str(row[key_info]):\n",
    "                uk.append(row[column_name])\n",
    "\n",
    "        output = output.rstrip(',')\n",
    "        \n",
    "        output += pk\n",
    "\n",
    "        output += CreateUniqueKeyOutput(uk)\n",
    "\n",
    "        # output += CreateForeignKeyOutput(fk)\n",
    "\n",
    "    output = output.rstrip(',')\n",
    "\n",
    "    # print(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TablesCreationWithTimestamp(df):\n",
    "    # Run the loop for each table \n",
    "    tables = df.groupby(t_name)\n",
    "\n",
    "    # Initialize output string\n",
    "    output = ''\n",
    "\n",
    "    for table_name, table in tables:\n",
    "\n",
    "        # Initialize variables for edges cases (CONSTRAINTS (PRIMARY KEYS & UNIQUE KEYS), TIMESTAMPS)\n",
    "        constraints = ''\n",
    "        uk = []\n",
    "        timestamp_flag = False\n",
    "\n",
    "        output += f'\\nCREATE OR REPLACE TABLE {schema}.{table_name} \\n('\n",
    "\n",
    "        for i, row in table.iterrows():\n",
    "\n",
    "            # if row[datatype] == 'TIMESTAMP(3)': #DW_CREAT_DTTM TIMESTAMP DEFAULT CURRENT_TIMESTAMP() COMMENT 'timestamp when record was created in the dw.'\n",
    "            #     output += f'\\n\\t {row[column_name]} TIMESTAMP DEFAULT CURRENT_TIMESTAMP() COMMENT \"{row[column_comment]}\",'\n",
    "            #     timestamp_flag = True\n",
    "            # else:\n",
    "            output += f'\\n\\t {row[column_name]} {row[datatype]} {row[nullability]} COMMENT \"{row[column_comment]}\",'\n",
    "            \n",
    "            if row[key_info] == 'PRIMARY KEY':\n",
    "                constraints += f',\\n\\t CONSTRAINT {table_name}_PK PRIMARY KEY ({row[column_name]})'\n",
    "            if row[key_info] == 'UNIQUE KEY':\n",
    "                uk.append(row[column_name])\n",
    "\n",
    "        output = output.rstrip(',')\n",
    "        \n",
    "        output += constraints\n",
    "\n",
    "        if len(uk) > 0:\n",
    "            uk_output = f',\\n\\t CONSTRAINT {table_name}_AK1 UNIQUE ('\n",
    "            for key in uk:\n",
    "                uk_output += ''+key\n",
    "            uk_output += ')'\n",
    "            output += uk_output\n",
    "            uk = []\n",
    "\n",
    "        if timestamp_flag:\n",
    "            output += f',\\n\\t SYSTEMTIMESTAMP TIMESTAMP'\n",
    "\n",
    "        output += '\\n),'\n",
    "    output = output.rstrip(',')\n",
    "    print(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipe and Stage Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateStageAndPipe(df, env, db, schema, format):\n",
    "    tables = df.groupby(t_name)\n",
    "    output = ''\n",
    "\n",
    "    for table_name, table in tables:\n",
    "        output += f'\\n-----{table_name}---------------------------------------------------------------------------'\n",
    "\n",
    "        output += f'\\nCREATE OR REPLACE STAGE {table_name}_STAGE \\n\\t copy_options = (on_error=\"skip_file\");\\n\\n'\n",
    "\n",
    "        output += f'CREATE OR REPLACE PIPE {db}.{schema}.{table_name}_PIPE AS \\nCOPY INTO {db}.{schema}.{table_name}('\n",
    "        for i, row in table.iterrows():\n",
    "            output += f'\\n\\t{row[column_name]},'\n",
    "        output = output.rstrip(',')\n",
    "\n",
    "        output += ')\\nFROM (SELECT'\n",
    "        for i, row in table.iterrows():\n",
    "            output += f'\\n\\tt.$1: {row[column_name]},'\n",
    "        output = output.rstrip(',')\n",
    "\n",
    "        output += f'\\nFROM @{table_name} t) \\nfile_format = (format_name = {env.lower()}_{format}_format);\\n'\n",
    "\n",
    "    # print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Foundation Table files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT:\n",
    "# CREATE TABLE FOUNDATION.DW_MBR_PCP LIKE ETL.DW_MBR_PCP\n",
    "# ...\n",
    " \n",
    "def CreateFoundationTables(df):\n",
    "    tables = df.groupby(t_name)\n",
    "    output = ''\n",
    "\n",
    "    for table_name, table in tables:\n",
    "        output += f'CREATE TABLE FOUNDATION.{table_name} LIKE ETL.{table_name};\\n'\n",
    "\n",
    "    # print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create afterMigrateError.sql files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT:\n",
    "# DELETE FROM \"ECT_DEV_ELIGIBILITY_DB\".\"ETL\".\"flyway_schema_history_memberpcp\" WHERE \"success\" = 0;\n",
    "\n",
    "def CreateAfterMigrateError(db, schema, flyway_history):\n",
    "    return f'DELETE FROM \"{db}\".\"{schema}\".\"{flyway_history}\" WHERE \"success\" = 0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Format files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT:\n",
    "# create or replace file format prd_avro_format\n",
    "#   type = avro;\n",
    "\n",
    "def CreateFormatFile(env, format):\n",
    "    return f'create or replace file format {env.lower()}_{format}_format\\n\\ttype = {format}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check directories for storing files, create new directories if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "paths = ['ddls', 'ddls/dev', 'ddls/stg', 'ddls/prd']\n",
    "\n",
    "# Create directories for files\n",
    "for p in paths:\n",
    "  if not path.isdir(p):\n",
    "    os.mkdir(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to file for each environment (dev, stg, prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some variables that are not found in the excel doc.\n",
    "envs = ['DEV', 'STG', 'PRD'] # Files need to be created for all 4 envs. \n",
    "schema = 'ETL'\n",
    "format = 'json' # For ADD {format} FORMAT.sql file.\n",
    "version = \"V1\" # For flyway versioning.\n",
    "flyway_history = \"flyway_schema_history_member_pcp\" #Check which flyway schema history your project should be using.\n",
    "\n",
    "for env in envs:\n",
    "    \n",
    "    db = f'ECT_{env}_ELIGIBILITY'\n",
    "\n",
    "    with open(f'ddls/{env}/{version}__CREATE_ETL_TABLES.sql', 'w') as f:\n",
    "        f.write(CreateETLTables(df, schema))\n",
    "        \n",
    "    with open(f'ddls/{env}/{version}__CREATE_STAGE_AND_PIPES.sql', 'w') as f:\n",
    "        f.write(CreateStageAndPipe(df, env, db, schema, format))\n",
    "    \n",
    "    with open(f'ddls/{env}/{version}__CREATE_FOUNDATION_TABLES.sql', 'w') as f:\n",
    "        f.write(CreateFoundationTables(df))\n",
    "\n",
    "    with open(f'ddls/{env}/afterMigrateError.sql', 'w') as f:\n",
    "        f.write(CreateAfterMigrateError(db, schema, flyway_history))\n",
    "\n",
    "    with open(f'ddls/{env}/{version}__ADD {format.upper()} FORMAT.sql', 'w') as f:\n",
    "        f.write(CreateFormatFile(env, format))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
